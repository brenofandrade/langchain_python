import os
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate


OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
model = "gpt-3.5-turbo"

# parÃ¢metros
numero_de_dias = int(input("Insira quantos dias de viagem vocÃª deseja: "))
quantidade_pessoas = int(input("Informe a quantidade de pessoas na famÃ­lia: "))
atividade = input("Insira a atividade desejada: ")
destino = input("Informe o destino (Se nÃ£o tiver preferÃªncia deixe em branco): ").strip()

# with open('prompts/prompt_turismo_v1.txt', 'r') as f:
#     instruction = f.read()

instruction = "Crie um roteiro de viagem de {dias} dias, para uma famÃ­lia com {quantidade_pessoas} crianÃ§as, que gostam de {atividade}" 

if destino:
    instruction += ", na localidade de {local}."
else:
    instruction += "."

local = destino if destino else ""

# Template
prompt_template = PromptTemplate.from_template(instruction)

# Prompt
prompt = prompt_template.format(
    dias=numero_de_dias,
    quantidade_pessoas = quantidade_pessoas,
    atividade = atividade,
    local = local
    )

# print("\nðŸ“‹ Prompt gerado:")
# print(prompt)


llm = ChatOpenAI(
    api_key=OPENAI_API_KEY,
    model=model, 
    temperature=0.5)

resposta = llm.invoke(prompt)

print(resposta.content)